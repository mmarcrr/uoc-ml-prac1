---
title: "Predicción de los splice junctions"
author: "Marc Rodriguez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: scholar.bib
lang: en
output:
  pdf_document:
    toc: true
    toc_depth: 2
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
  html_document:
    toc: TRUE
    toc_depth: 2
    fig_caption: TRUE
    toc_float:
      collapsed: TRUE
      smooth_scroll: TRUE
geometry: margin=1in
fontfamily: libertine
fontsize: 11pt
params:
    
    
    
    file_in: "splice.txt"
    kvalues: !r c(1, 5, 11, 21, 51, 71)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, include=FALSE}
# Load packages
library(knitr)
library(stringr)
library(class)
library(gmodels)
library(kableExtra)
library(ROCR)
library(pROC)

library(ggseqlogo)
require(knitr, quietly = TRUE)

```

El algoritmo kNN utiliza el método de clasificación de vecinos más cercanos. Las fortalezas y debilidades de este algoritmo son:

| **Fortalezas**    | **Debilidades**  | 
| ------------------------ |:------------------------------------------------------- |
|* Simple y eficaz  |* No produce un modelo, que limita la capacidad de encontrar conocimientos novedosos en relaciones entre características
|* No hace suposiciones sobre la distribución de datos subyacente | * Fase de clasificación lenta
|* Fase de entrenamiento ésrápida | * Requiere una gran cantidad de memoria
| | * Características nominales y datos faltantes requieren procesamiento adicional

El algoritmo kNN comienza con un conjunto de datos de entrenamiento compuesto por ejemplos que son clasificados en varias categorías, etiquetadas por una variable nominal. Supongamos que nosotros tener un conjunto de datos de prueba que contenga ejemplos sin etiquetar que, de lo contrario, tengan el mismo características como los datos de entrenamiento. Para cada registro en el conjunto de datos de prueba, kNN identifica k registros en los datos de entrenamiento que son los "más cercanos" en similitud, donde k es un número entero especificado de antemano. A la instancia de prueba sin etiqueta se le asigna la clase de la mayoría de los k vecinos mas cercanos.

Apesar de ser un algoritmos simple, es capaz de abordar tareas extremadamente complejas, como identificar masas cancerosas. 


## Predicción de los splice junctions
Los splice junctions son puntos en una secuencia de ADN en los que se elimina el ADN “superfluo” durante el proceso de síntesis de proteínas en organismos superiores. El problema que se plantea en este conjunto de datos es reconocer, dada una secuencia de ADN, los límites entre los exones (las partes de la secuencia de ADN retenidas después del splicing) y los intrones (las partes de la secuencia de ADN que se cortan). Este problema consta de dos subtareas: reconocer los límites exón/intrón (denominados sitios EI) y reconocer los límites intrón/exón (sitios IE). En la comunidad biológica, las fronteras de la IE se denominan acceptors, mientras que las fronteras de la EI se denominan donors.

Todos los ejemplos fueron tomados de Genbank 64.1. Las categorías “EI” e “IE” incluyen “genes con splicing” de los primates en Genbank 64.1. Los ejemplos de no splicing fueron tomados de secuencias que se sabe que no incluyen un sitio de splicing. Los datos estan disponibles en la PEC en el fichero splice.txt. El archivo contiene 3190 filas que corresponden a las distintas secuencias, y 3 columnas separadas por coma. La primera columna correspondiente a la clase de la secuencia (EI, IE o N), la segunda columna con el nombre identificador de la secuencia y la tercera columna  con la secuencia propiamente. Tratándose de secuencias de ADN, aparecerán los nucleótidos identificados de
manera estándar con las letras A, G, T y C. Además, aparecen otros caracteres entre los caracteres estándar,
D, N, S y R, que indican ambigüedad según la siguiente tabla:

| **caracter** | **significado** |
| ------------ |:--------------- |
| D | A o G o T |
| N | A o G o C o T |
| S | C o G |
| R | A o G |

La manera elegida para representar los datos es un paso crucial en los algoritmos. En el caso que nos ocupa, análisis basados en secuencias, se usará la codificación one-hot. La codificación one-hot representa cada nucleótido por un vector de 8 componentes, con 7 de ellas a 0 y una a 1. Pongamos por ejemplo, el nucleótido A se representa por (1,0,0,0,0,0,0,0), el nucleótido G por (0,1,0,0,0,0,0,0), el T por (0,0,1,0,0,0,0,0) y, finalmente, la C por (0,0,0,1,0,0,0,0) y los caracteres de ambigüedad los representaremos, la D por (0,0,0,0,1,0,0,0), la N por (0,0,0,0,0,1,0,0), la S por (0,0,0,0,0,0,1,0) y la R por (0,0,0,0,0,0,0,1).


## función en R one-hot encoding

función en R que implementa la codificación “one-hot” (one-hot encoding) de las secuencias, Recibe como paramentro la secuencia y el espacio de posibles caracteres
```{r one-hote}
space<-c("A","G","T","C","D","N","S","R")
encode.onehot<-function(sequence,space){
  seq.splited<-unlist(strsplit(str_trim(sequence),""))
  sapply(seq.splited,function(code){match(space,code,nomatch=0)}, simplify = TRUE)
}
```

Ejemplo de aplicación monstrando el resultado como vector 


```{r one-hote-example}
nuc_seq="CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCCTTCGAGCCAGTCTG"
c(t(encode.onehot(nuc_seq,space)))
```

## Desarrollo de un script en R que implementa un clasificador knn. 
### (A1) Leer los datos del fichero splice.txt 

Leemos el fichero `r params$file_in` que es un parámetro del documento 

```{r read}
data_in <- read.csv(file.path(params$file_in), header=FALSE)

```

### (A2)breve descripción de los datos
Observamos algunos valores del fichero
```{r}
head(data_in)
```
vemos una descripcion de los datos
```{r}
str(data_in)
```
Los datos leidos del fichero `r params$file_in` contiene 3190 filas que corresponden a las distintas secuencias, y 3 columnas separadas por coma. La primera columna correspondiente a la clase de la secuencia (EI, IE o N), la segunda columna con el nombre identificador de la secuencia y la tercera columna  con la secuencia propiamente.

Analizamos la cantidad de secuencias de cada clase, nos dara una idea del balanceo de los datos,
```{r}
knitr::kable(table(data_in[,1]), "pipe",caption="Tabla del número de sequencia de nucleotidos según la clase")
```
### (B) Transformar las secuencias de nucleótidos en vectores numéricos usando la función de transformación desarrollada anteriormente. 

Generamos el dataframe los mas parecido al fichero splice_oh.RData aplicando la función onehot creada anteriormente.
También se renombrar las columnas v1 por class y v2 por seq_name
```{r}
mysplice<-data.frame(data_in[1],data_in[2],t(apply(data_in[3],1,encode.onehot,space)))
colnames(mysplice)[1] <- "class"
colnames(mysplice)[2] <- "seq_name"
```

### (C)Para el subset formado por las secuencias de las clases “EI” y “N”, y para el subset formado por las secuencias de las clases “IE” y “N”, realizar la implementación del algoritmo knn

Creamos los subset de "EI"-"N" y "IE"-"N" 
```{r}
EIN.data <- subset(mysplice,mysplice$class %in% c("N","EI"))
IEN.data <- subset(mysplice,mysplice$class %in% c("N","IE"))
```
Aplicamos la funcion onehot a la columna 3 que es la que contiene las sequencias.  

```{r}
EIN.onehot <-subset(EIN.data,select=-c(1,2))
IEN.onehot <-subset(IEN.data,select=-c(1,2))
```
Utilizando la semilla aleatoria 123 para separar los datos en dos partes, una parte para training
(67%) y una parte para test (33%).
```{r}
set.seed(123)

#generamos un sample de  2/3
EIN.train<-sample(1:nrow(EIN.onehot),round(nrow(EIN.onehot)*2/3,0))
IEN.train<-sample(1:nrow(EIN.onehot),round(nrow(IEN.onehot)*2/3,0))
EIN.train
```

Usamos la lista quenerada con la funcion sample de 2/3 de las posiciones para crear los subsets de entranamiento de EI-N y IE-N
```{r}
EIN.training<-EIN.onehot[EIN.train,]
IEN.training<-IEN.onehot[IEN.train,]

```
El resto de valores los usaremos para el subset de test

```{r}
EIN.test<-EIN.onehot[-EIN.train,]
IEN.test<-IEN.onehot[-IEN.train,]
```

Creamos las etiquetas de entrenamiento y validacion de las clases
```{r}
EIN.class_training<-EIN.data[EIN.train,1]
EIN.class_test<-EIN.data[-EIN.train,1]

IEN.class_training<-IEN.data[IEN.train,1]
IEN.class_test<-IEN.data[-IEN.train,1]

```

Aplicamos la función knn sobre los datos divididos para ver el funcionamiento
```{r}
EIN.test_pred <- knn(train =EIN.training, test = EIN.test, cl = EIN.class_training, k=20)
IEN.test_pred <- knn(train =IEN.training, test = IEN.test, cl = IEN.class_training, k=20)

```
Generamos la tabla para ver el rendimiento  del algoritmo

primero sobre las clases EI N
```{r}
CrossTable(x = EIN.class_test, y = EIN.test_pred , prop.chisq=FALSE)
```
Y Sobre las clases IE N
```{r}
CrossTable(x = IEN.class_test, y = IEN.test_pred , prop.chisq=FALSE)
```
### (C)Aplicar el knn (k = `r params$ksvalues`) basado en el training para predecir que secuencias del test son secuencias con puntos de splicing (splice junctions) o no. Además, realizar una curva ROC para cada k y mostrar el valor de AUC.

Creamos una funcion para pode aplicar la misma sobre las diferentes classes
```{r}
testknn <-function(data.training,data.test,data.class_training,data.class_test,ks){
  summary <- data.frame(ks, FN=NA, FP=NA, mal_clas=NA)
  j <- 0
  for (i in ks){
    j <- j +1
    class_test_pred <-knn(train =data.training, test = data.test, cl = data.class_training, k=i)
    conf.mat <- CrossTable(x = data.class_test, y = class_test_pred, prop.chisq=FALSE)
    summary[j,2:4] <- c(conf.mat$t[2,1], conf.mat$t[1,2], ((conf.mat$t[1,2]+conf.mat$t[2,1])/sum(conf.mat$t))*100)
  }
  summary
}
```

aplicamos la funcion testknn sobre las clases EI N 
```{r}
require(knitr, quietly = TRUE)
EIN.resum<-testknn(EIN.training,EIN.test,EIN.class_training,EIN.class_test,params$kvalues)
```


````{r message=FALSE}
kable(EIN.resum, col.names=c("valor k", "# falsos negativos","# falsos positivos", "% mal clasificados"),
align= c("l","c","c","c"), caption= paste("Algoritmo kNN: ",params$file_in ,sep=""))
```

aplicamos la funcion testknn sbore las clases IE N
```{r  message=FALSE}
require(knitr, quietly = TRUE)
IEN.resum<-testknn(IEN.training,IEN.test,IEN.class_training,IEN.class_test,params$kvalues)
```

```{r message=FALSE}
kable(IEN.resum, col.names=c("valor k", "# falsos negativos","# falsos positivos", "% mal clasificados"),align= c("l","c","c","c"), caption= paste("Algoritmo kNN: ",params$file_in ,sep=""))

```

Creamos una funcion para representar las curvas ROC y mostrar el valor de AUC para los k valores `r params$kvalues` 

```{r}
library(pROC)
myROC <-function(data.training,data.test,data.class_training,data.class_test,ks){
  par(mfrow=c(3,2))
  for (i in ks){
    test_pred <-knn(train = data.training, test = data.test, cl = data.class_training, k=i,prob = TRUE)
    prob <- attr(test_pred, "prob")
    probN <- ifelse(test_pred == "N" , prob, 1-prob)
    res <- auc(data.class_test,probN)
    pred_knn <- ROCR::prediction(probN, data.class_test)
    pred_knn <- performance(pred_knn, "tpr", "fpr")
    plot(pred_knn, avg= "threshold", colorize=T, lwd=3, main=paste("curava ROC para  k: ", i, "con porcentage de auc=", round(res,4)))
  }
}

```

Hemos parametrizado las diferentes ks proporcionadas por el enunciado para que sea aplicable el mismo informe a diferentes configuraciones
mostramos en los graficos el valor de "auc" que es el area por debajo de la curva ROC. Que nos da una idea de como de buena es la clasificacion de los valores. 

Primero mostramos las curvas de EI-N
```{r}
myROC(EIN.training,EIN.test,EIN.class_training,EIN.class_test,params$kvalues)
```
A continuzcoin mostramos las curvas IE-N
```{r}
myROC(IEN.training,IEN.test,IEN.class_training,IEN.class_test,params$kvalues)

```

En las curvas igual que se puede reflejar en las tablas podemos ver que la mejor agrupación resulta ser con k=21 

## Representar la sequencia logo de las tres clases de secuencias.

Para crear logos de secuencias, las secuencias relacionadas de ADN, ARN o proteínas, o bien secuencias de ADN que comparten lugares de unión conservados, son alineadas hasta que las partes más conservadas crean buenos alineamientos. Se puede crear entonces un logo de secuencias a partir del alineamiento múltiple de secuencias conservadas. El logo de secuencias pondrá de manifiesto el grado de conservación de los residuos en cada posición: un menor número de residuos diferentes provocará mayor tamaño en las letras, ya que la conservación es mejor en esa posición. Los residuos diferentes en la misma posición se escalarán de acuerdo a su frecuencia. Los logos de secuencias pueden usarse para representar sitios conservados de unión al ADN, donde quedan unidos los factores de transcripción.


```{r}

ggseqlogo(str_trim(subset(data_in, V1 == "IE")$V3))

```
Las letras de mayor altura representarán residuos únicos, y por consenso, las bases más conservadas se representan en la parte más alta de las pilas de residuos y, a la inversa, las menos conservadas irán ocupando, de forma proporcional, las posiciones inferiores, es decir, representar sitios conservados de unión al ADN, donde quedan unidos los factores de transcripción

```{r}
ggseqlogo(str_trim(subset(data_in, V1 == "EI")$V3))
```


```{r}
ggseqlogo(str_trim(subset(data_in, V1 == "N")$V3))
```
La represntacion de la clase N no muestra claramente donde quedan unidos los factores de transcripción

# Bibliografia

nocite: |
  @*
