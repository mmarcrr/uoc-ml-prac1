---
title: "Algoritmo k-NN"
author: "Marc Rodriguez"
date: "10/24/2021"
output: html_document
params:
    file_in: "splice.txt"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## implementacion codificación “one-hot”

```{r one-hote}
library(stringr)

encode.onehot<-function(sequence){
codes<-c("A","G","T","C","D","N","S","R")
seq.splited<-unlist(strsplit(str_trim(sequence),""))
c(t(sapply(seq.splited,function(x){match(codes,x,nomatch=0)})))
}

nuc_seq="CCAGCTGCATCACAGGAGGCCAGCGAGCAGGTCTGTTCCAAGGGCCTTCGAGCCAGTCTG"
example<-encode.onehot(nuc_seq)
typeof(example)


```


```{r one-hote2}
library(stringr)
#seq.splited<-unlist(strsplit(nuc_seq,""))
#output<-sapply(seq.splited,function(seq){match(codes,seq,nomatch=0)})
#c(t(output))
(nuc_seq)
```


```{r read}
file1="splice.txt"
data_in <- read.csv(file.path(params$file_in), header=FALSE)
data_in
```
```{r}
summary(data_in)
```
```{r}
encode.onehot<-function(sequence){
codes<-c("A","G","T","C","D","N","S","R")
seq.splited<-unlist(strsplit(str_trim(sequence),""))
sapply(seq.splited,function(x){match(codes,x,nomatch=0)}, simplify = TRUE)
}

mysplice<-data.frame(data_in[1],data_in[2],t(apply(data_in[3],1,encode.onehot)))
colnames(mysplice)[1] <- "class"
colnames(mysplice)[2] <- "seq_name"


```


```{r}

EIN.data <- subset(mysplice,mysplice$class %in% c("N","EI"))
IEN.data <- subset(mysplice,mysplice$class %in% c("N","IE"))
EIN.onehot <-subset(EIN.data,select=-c(1,2))
IEN.onehot <-subset(IEN.data,select=-c(1,2))
```
```{r}
################## data spliting
EIN.train<-sample(1:nrow(EIN.onehot),round(2*nrow(EIN.onehot)/3,0))
IEN.train<-sample(1:nrow(EIN.onehot),round(2*nrow(IEN.onehot)/3,0))

```


```{r}
# create training and test data
EIN.training<-EIN.onehot[EIN.train,]
EIN.test<-EIN.onehot[-EIN.train,]
IEN.training<-IEN.onehot[IEN.train,]
IEN.test<-IEN.onehot[-IEN.train,]

# create labels for training and test data
EIN.class_training<-EIN.data[EIN.train,1]
EIN.class_test<-EIN.data[-EIN.train,1]
# create labels for training and test data
IEN.class_training<-IEN.data[IEN.train,1]
IEN.class_test<-IEN.data[-IEN.train,1]

```
```{r}
############### libraries loading
library(class) # knn
############## data prediction

set.seed(123) #fijar la semilla para el inicio del clasificador
EIN.test_pred <- knn(train =EIN.training, test = EIN.test, cl = EIN.class_training, k=20)
IEN.test_pred <- knn(train =IEN.training, test = IEN.test, cl = IEN.class_training, k=20)

```


```{r}
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
############ evaluating model performance
CrossTable(x = EIN.class_test, y = EIN.test_pred , prop.chisq=FALSE)
```
```{r}
# load the "gmodels" library
library(gmodels)
# Create the cross tabulation of predicted vs. actual
############ evaluating model performance
CrossTable(x = IEN.class_test, y = IEN.test_pred , prop.chisq=FALSE)
```
```{r}
load("splice_oh.Rdata")
splice_subset<-subset(output,select=-c(1,2))
```
```{r}

testknn <-function(data.training,data.test,data.class_training,data.class_test,ks){
  
  resum <- data.frame(ks, FN=NA, FP=NA, mal_clas=NA)
  j <- 0
  for (i in ks){
    j <- j +1
    class_test_pred <-knn(train =data.training, test = data.test, cl = data.class_training, k=i)
    conf.mat <- CrossTable(x = data.class_test, y = class_test_pred, prop.chisq=FALSE)
    resum[j,2:4] <- c(conf.mat$t[2,1], conf.mat$t[1,2], ((conf.mat$t[1,2]+conf.mat$t[2,1])/sum(conf.mat$t))*100)
  }
  resum
}
```


```{r}
ks <- c(1, 5, 11, 21, 51, 71)
require(knitr, quietly = TRUE)
EIN.resum<-testknn(EIN.training,EIN.test,EIN.class_training,EIN.class_test,ks)
kable(EIN.resum, col.names=c("valor k", "# falsos negativos","# falsos positivos", "% mal clasificados"),
align= c("l","c","c","c"), caption= paste("Algoritmo kNN: ",params$file_in ,sep=""))
```
```{r}
require(knitr, quietly = TRUE)
IEN.resum<-testknn(IEN.training,IEN.test,IEN.class_training,IEN.class_test,ks)
kable(IEN.resum, col.names=c("valor k", "# falsos negativos","# falsos positivos", "% mal clasificados"),
align= c("l","c","c","c"), caption= paste("Algoritmo kNN: ",params$file_in ,sep=""))

```
```{r}
# try several different values of k
library(pROC)
library(class)
library(ROCR)

myROC <-function(data.training,data.test,data.class_training,data.class_test,ks){
  
  par(mfrow=c(3,2))
  for (i in ks){
    test_pred <-knn(train = data.training, test = data.test, cl = data.class_training, k=i,prob = TRUE)
    prob <- attr(test_pred, "prob")
    prob1 <- ifelse(test_pred == "N" , prob, 1-prob)
    res <- auc(data.class_test,prob1)

  pred_knn <- ROCR::prediction(prob1, data.class_test)
  pred_knn <- performance(pred_knn, "tpr", "fpr")
  plot(pred_knn, avg= "threshold", colorize=T, lwd=3, main=paste("ROC curve, k: ", i, ", auc=", round(res,4)))
  }
}

```
```{r}
ks <- c(1, 5, 11, 21, 51, 71)
myROC(EIN.training,EIN.test,EIN.class_training,EIN.class_test,ks)

```
```{r}
myROC(IEN.training,IEN.test,IEN.class_training,IEN.class_test,ks)

```
```{r}
library(ggseqlogo)

ggseqlogo(str_trim(subset(data_in, V1 == "IE")$V3))

```
```{r}
ggseqlogo(str_trim(subset(data_in, V1 == "EI")$V3))
```


```{r}
ggseqlogo(str_trim(subset(data_in, V1 == "N")$V3))
```

